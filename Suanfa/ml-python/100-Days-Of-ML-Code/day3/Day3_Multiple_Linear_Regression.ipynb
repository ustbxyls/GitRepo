{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "data = pd.read_csv('50_Startups.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']]\n",
      "[192261.83 191792.06 191050.39]\n"
     ]
    }
   ],
   "source": [
    "# state feature to one-hot\n",
    "# noramlize\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "print(X[:3])\n",
    "print(Y[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LabelEncoder in module sklearn.preprocessing.label:\n",
      "\n",
      "class LabelEncoder(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Encode labels with value between 0 and n_classes-1.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_targets>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape (n_class,)\n",
      " |      Holds the label for each class.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  `LabelEncoder` can be used to normalize labels.\n",
      " |  \n",
      " |  >>> from sklearn import preprocessing\n",
      " |  >>> le = preprocessing.LabelEncoder()\n",
      " |  >>> le.fit([1, 2, 2, 6])\n",
      " |  LabelEncoder()\n",
      " |  >>> le.classes_\n",
      " |  array([1, 2, 6])\n",
      " |  >>> le.transform([1, 1, 2, 6]) #doctest: +ELLIPSIS\n",
      " |  array([0, 0, 1, 2]...)\n",
      " |  >>> le.inverse_transform([0, 0, 1, 2])\n",
      " |  array([1, 1, 2, 6])\n",
      " |  \n",
      " |  It can also be used to transform non-numerical labels (as long as they are\n",
      " |  hashable and comparable) to numerical labels.\n",
      " |  \n",
      " |  >>> le = preprocessing.LabelEncoder()\n",
      " |  >>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
      " |  LabelEncoder()\n",
      " |  >>> list(le.classes_)\n",
      " |  ['amsterdam', 'paris', 'tokyo']\n",
      " |  >>> le.transform([\"tokyo\", \"tokyo\", \"paris\"]) #doctest: +ELLIPSIS\n",
      " |  array([2, 2, 1]...)\n",
      " |  >>> list(le.inverse_transform([2, 2, 1]))\n",
      " |  ['tokyo', 'tokyo', 'paris']\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  sklearn.preprocessing.OneHotEncoder : encode categorical integer features\n",
      " |      using a one-hot aka one-of-K scheme.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LabelEncoder\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  fit(self, y)\n",
      " |      Fit label encoder\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  fit_transform(self, y)\n",
      " |      Fit label encoder and return encoded labels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape [n_samples]\n",
      " |  \n",
      " |  inverse_transform(self, y)\n",
      " |      Transform labels back to original encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : numpy array of shape [n_samples]\n",
      " |  \n",
      " |  transform(self, y)\n",
      " |      Transform labels to normalized encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      y : array-like of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape [n_samples]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "help(LabelEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(X[:, -1])\n",
    "X[:, -1] = integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 2, 1, 2, 0, 1, 2, 0, 1, 0, 1, 0, 1, 2, 0, 2, 1, 2, 0, 2,\n",
       "       1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1, 0, 2, 1, 0, 2, 0, 0, 1, 0, 2,\n",
       "       0, 2, 1, 0, 2, 0], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165349.2, 136897.8, 471784.1, 2],\n",
       "       [162597.7, 151377.59, 443898.53, 0],\n",
       "       [153441.51, 101145.55, 407934.54, 1],\n",
       "       [144372.41, 118671.85, 383199.62, 2],\n",
       "       [142107.34, 91391.77, 366168.42, 1],\n",
       "       [131876.9, 99814.71, 362861.36, 2],\n",
       "       [134615.46, 147198.87, 127716.82, 0],\n",
       "       [130298.13, 145530.06, 323876.68, 1],\n",
       "       [120542.52, 148718.95, 311613.29, 2],\n",
       "       [123334.88, 108679.17, 304981.62, 0],\n",
       "       [101913.08, 110594.11, 229160.95, 1],\n",
       "       [100671.96, 91790.61, 249744.55, 0],\n",
       "       [93863.75, 127320.38, 249839.44, 1],\n",
       "       [91992.39, 135495.07, 252664.93, 0],\n",
       "       [119943.24, 156547.42, 256512.92, 1],\n",
       "       [114523.61, 122616.84, 261776.23, 2],\n",
       "       [78013.11, 121597.55, 264346.06, 0],\n",
       "       [94657.16, 145077.58, 282574.31, 2],\n",
       "       [91749.16, 114175.79, 294919.57, 1],\n",
       "       [86419.7, 153514.11, 0.0, 2],\n",
       "       [76253.86, 113867.3, 298664.47, 0],\n",
       "       [78389.47, 153773.43, 299737.29, 2],\n",
       "       [73994.56, 122782.75, 303319.26, 1],\n",
       "       [67532.53, 105751.03, 304768.73, 1],\n",
       "       [77044.01, 99281.34, 140574.81, 2],\n",
       "       [64664.71, 139553.16, 137962.62, 0],\n",
       "       [75328.87, 144135.98, 134050.07, 1],\n",
       "       [72107.6, 127864.55, 353183.81, 2],\n",
       "       [66051.52, 182645.56, 118148.2, 1],\n",
       "       [65605.48, 153032.06, 107138.38, 2],\n",
       "       [61994.48, 115641.28, 91131.24, 1],\n",
       "       [61136.38, 152701.92, 88218.23, 2],\n",
       "       [63408.86, 129219.61, 46085.25, 0],\n",
       "       [55493.95, 103057.49, 214634.81, 1],\n",
       "       [46426.07, 157693.92, 210797.67, 0],\n",
       "       [46014.02, 85047.44, 205517.64, 2],\n",
       "       [28663.76, 127056.21, 201126.82, 1],\n",
       "       [44069.95, 51283.14, 197029.42, 0],\n",
       "       [20229.59, 65947.93, 185265.1, 2],\n",
       "       [38558.51, 82982.09, 174999.3, 0],\n",
       "       [28754.33, 118546.05, 172795.67, 0],\n",
       "       [27892.92, 84710.77, 164470.71, 1],\n",
       "       [23640.93, 96189.63, 148001.11, 0],\n",
       "       [15505.73, 127382.3, 35534.17, 2],\n",
       "       [22177.74, 154806.14, 28334.72, 0],\n",
       "       [1000.23, 124153.04, 1903.93, 2],\n",
       "       [1315.46, 115816.21, 297114.46, 1],\n",
       "       [0.0, 135426.92, 0.0, 0],\n",
       "       [542.05, 51743.15, 0.0, 2],\n",
       "       [0.0, 116983.8, 45173.06, 0]], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['California', 'Florida', 'New York'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\RaiYi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['New York', 'California', 'Florida', 'New York', 'Florida',\n",
       "       'New York', 'California', 'Florida', 'New York', 'California',\n",
       "       'Florida', 'California', 'Florida', 'California', 'Florida',\n",
       "       'New York', 'California', 'New York', 'Florida', 'New York',\n",
       "       'California', 'New York', 'Florida', 'Florida', 'New York',\n",
       "       'California', 'Florida', 'New York', 'Florida', 'New York',\n",
       "       'Florida', 'New York', 'California', 'Florida', 'California',\n",
       "       'New York', 'Florida', 'California', 'New York', 'California',\n",
       "       'California', 'Florida', 'California', 'New York', 'California',\n",
       "       'New York', 'Florida', 'California', 'New York', 'California'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_encoder.inverse_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(OneHotEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode\n",
    "onehot_encoder = OneHotEncoder(categorical_features=[3])\n",
    "onehot = onehot_encoder.fit_transform(X).toarray()\n",
    "onehot[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = onehot\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MinMaxScaler in module sklearn.preprocessing.data:\n",
      "\n",
      "class MinMaxScaler(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  Transforms features by scaling each feature to a given range.\n",
      " |  \n",
      " |  This estimator scales and translates each feature individually such\n",
      " |  that it is in the given range on the training set, i.e. between\n",
      " |  zero and one.\n",
      " |  \n",
      " |  The transformation is given by::\n",
      " |  \n",
      " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      " |      X_scaled = X_std * (max - min) + min\n",
      " |  \n",
      " |  where min, max = feature_range.\n",
      " |  \n",
      " |  This transformation is often used as an alternative to zero mean,\n",
      " |  unit variance scaling.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  feature_range : tuple (min, max), default=(0, 1)\n",
      " |      Desired range of transformed data.\n",
      " |  \n",
      " |  copy : boolean, optional, default True\n",
      " |      Set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  min_ : ndarray, shape (n_features,)\n",
      " |      Per feature adjustment for minimum.\n",
      " |  \n",
      " |  scale_ : ndarray, shape (n_features,)\n",
      " |      Per feature relative scaling of the data.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_* attribute.\n",
      " |  \n",
      " |  data_min_ : ndarray, shape (n_features,)\n",
      " |      Per feature minimum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_min_*\n",
      " |  \n",
      " |  data_max_ : ndarray, shape (n_features,)\n",
      " |      Per feature maximum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_max_*\n",
      " |  \n",
      " |  data_range_ : ndarray, shape (n_features,)\n",
      " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_range_*\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
      " |  >>>\n",
      " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      " |  >>> scaler = MinMaxScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      " |  >>> print(scaler.data_max_)\n",
      " |  [  1.  18.]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[ 0.    0.  ]\n",
      " |   [ 0.25  0.25]\n",
      " |   [ 0.5   0.5 ]\n",
      " |   [ 1.    1.  ]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[ 1.5  0. ]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  minmax_scale: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MinMaxScaler\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, feature_range=(0, 1), copy=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the minimum and maximum to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to compute the per-feature minimum and maximum\n",
      " |          used for later scaling along the features axis.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Undo the scaling of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          Input data that will be transformed. It cannot be sparse.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of min and max on X for later scaling.\n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when `fit` is not feasible due to very large number of `n_samples`\n",
      " |      or because X is read from a continuous stream.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : Passthrough for ``Pipeline`` compatibility.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Scaling features of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          Input data that will be transformed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 1.        , 0.65174393,\n",
       "        1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.98335946, 0.76197173,\n",
       "        0.94089337],\n",
       "       [0.        , 1.        , 0.        , 0.92798459, 0.37957895,\n",
       "        0.8646636 ],\n",
       "       [0.        , 0.        , 1.        , 0.87313643, 0.51299839,\n",
       "        0.81223513],\n",
       "       [0.        , 1.        , 0.        , 0.85943772, 0.30532804,\n",
       "        0.77613557]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.        , 1.        , 0.65174393,\n",
       "        1.        ],\n",
       "       [1.        , 0.        , 0.        , 0.98335946, 0.76197173,\n",
       "        0.94089337],\n",
       "       [0.        , 1.        , 0.        , 0.92798459, 0.37957895,\n",
       "        0.8646636 ],\n",
       "       [0.        , 0.        , 1.        , 0.87313643, 0.51299839,\n",
       "        0.81223513],\n",
       "       [0.        , 1.        , 0.        , 0.85943772, 0.30532804,\n",
       "        0.77613557]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = scaled_X \n",
    "X[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inversed = min_max_scaler.inverse_transform(scaled_X)\n",
    "inversed[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192261.83, 191792.06, 191050.39, 182901.99, 166187.94])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.99735461],\n",
       "       [0.99317808],\n",
       "       [0.94729239],\n",
       "       [0.85317138]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler_Y = MinMaxScaler()\n",
    "Y = min_max_scaler_Y.fit_transform(Y.reshape(-1,1))\n",
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1/4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00095851, -0.00197981,  0.0010213 ,  0.7271982 ,  0.03387809,\n",
       "         0.08911221]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16075123])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50545731],\n",
       "       [0.6620798 ],\n",
       "       [0.66556136],\n",
       "       [0.32112991],\n",
       "       [0.92351164],\n",
       "       [0.56535921],\n",
       "       [0.28951687],\n",
       "       [0.47346618],\n",
       "       [0.55992769],\n",
       "       [0.86326007],\n",
       "       [0.45672472],\n",
       "       [0.4116667 ],\n",
       "       [0.53933073]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = linear_regression.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023405663438078412"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
